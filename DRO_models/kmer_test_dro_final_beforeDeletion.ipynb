{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAlias' could not be imported from '/usr/lib/python3/dist-packages/typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#pip install pandas matplotlib seaborn scikit-learn numpy xgboost scipy rich shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "from rich.progress import track\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib as mpl\n",
    "from enum import Enum\n",
    "import shap\n",
    "import argparse\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dorothy/amr_ML/models_DRO/models_hypatia_beforeDeletion\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "# Save the model. Create the model folder if it does not exist\n",
    "os.makedirs('./models_dro', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results of the best model to a SVG file\n",
    "def plot_metrics(y_test, y_pred, classes = ['S', 'R'], filename='metrics.svg', cmap='crest'):\n",
    "    gs = plt.GridSpec(1, 2)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Change labels from 0, 1 to S and R\n",
    "    cm_df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    _ = ax0.annotate('A', xy=(-0.05, 1.02), xycoords=\"axes fraction\", fontsize=16, fontweight='bold')\n",
    "    _ = sns.heatmap(cm_df, annot=True, fmt='g', cmap=cmap, linewidths=0.5, annot_kws={\"size\": 14})  # Increase annotation size here\n",
    "    _ = plt.title('Confusion Matrix', fontsize=14)  # Title font size\n",
    "    _ = plt.xlabel('Predicted labels', fontsize=12)  # X-axis label font size\n",
    "    _ = plt.ylabel('True labels', fontsize=12)  # Y-axis label font size\n",
    "    _ = plt.xticks(fontsize=10)  # X-tick labels font size\n",
    "    _ = plt.yticks(fontsize=10)  # Y-tick labels font size\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    _ = ax1.annotate('B', xy=(-0.05, 1.02), xycoords=\"axes fraction\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    keys_to_plot = [key for key in clf_report.keys() if key not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "    df = pd.DataFrame(clf_report, columns=keys_to_plot).T\n",
    "\n",
    "    rows, cols = df.shape\n",
    "    mask = np.zeros(df.shape)\n",
    "    mask[:,cols-1] = True\n",
    "\n",
    "    ax1 = sns.heatmap(df, mask=mask, annot=True, cmap=cmap, fmt='.4g',\n",
    "                      vmin=0.0, vmax=1.0, linewidths=2, linecolor='white',\n",
    "                      annot_kws={\"size\": 12},  # Increase annotation size here\n",
    "                      yticklabels=classes)\n",
    "\n",
    "    # Then, let's add the support column by normalizing the colors in this column\n",
    "    mask = np.zeros(df.shape)\n",
    "    mask[:,:cols-1] = True    \n",
    "\n",
    "    ax1 = sns.heatmap(df, mask=mask, annot=True, cmap=cmap, cbar=False,\n",
    "                      linewidths=2, linecolor='white', fmt='.0f',\n",
    "                      vmin=df['support'].min(), vmax=df['support'].sum(),         \n",
    "                      norm=mpl.colors.Normalize(vmin=df['support'].min(),\n",
    "                                                vmax=df['support'].sum()),\n",
    "                      annot_kws={\"size\": 12},  # Increase annotation size here\n",
    "                      yticklabels=classes)\n",
    "            \n",
    "    _ = plt.title(\"Classification Report\", fontsize=14)  # Title font size\n",
    "    _ = plt.xticks(rotation=0, fontsize=10)  # X-tick labels font size\n",
    "    _ = plt.yticks(rotation=360, fontsize=10)  # Y-tick labels font size\n",
    "\n",
    "    # Save as SVG\n",
    "    plt.savefig(filename, dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Variables\n",
    "njobs = 21\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/data/dorothy/amr_ML/models_DRO/data/assemblies_test.txt', 'r') as f:\n",
    "    assemblies = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(kmer_size = 3):\n",
    "    print(f\"Loading data for kmer size {kmer_size}\")\n",
    "\n",
    "    # print to output file\n",
    "    with open(output, 'a') as f:\n",
    "        print(f\"Loading data for kmer size {kmer_size}\", file=f)\n",
    "    \n",
    "    # Make the final concatenated dataset \n",
    "    X_dna = np.load(f\"/data/dorothy/amr_ML/models_DRO/data/data/kmer_{kmer_size}_flatteneddna_.npy\", allow_pickle=True)\n",
    "    X_protein = np.load(f\"/data/dorothy/amr_ML/models_DRO/data/data/kmer_{kmer_size}_flattenedprotein_.npy\", allow_pickle=True)\n",
    "    X_rrna = np.load(f\"/data/dorothy/amr_ML/models_DRO/data/data/kmer_{kmer_size}_flattenedrrna_.npy\", allow_pickle=True)\n",
    "\n",
    "    X_rrna_subset = X_rrna[indices]\n",
    "    X_dna_subset = X_dna[indices]\n",
    "    X_protein_subset = X_protein[indices]\n",
    "    \n",
    "    del X_dna, X_protein, X_rrna\n",
    "\n",
    "    X = np.concatenate((X_dna_subset, X_rrna_subset, X_protein_subset), axis=1)\n",
    "    X = X.astype(np.int16)\n",
    "    y = antibiotic_binary\n",
    "\n",
    "     # Combine y and group labels for stratification\n",
    "    stratification_labels = [f\"{y_class}_{group}\" for y_class, group in zip(y, antibiogram_unique['genus'])]\n",
    "    \n",
    "    # Perform the 80-20 split with both stratification and group constraints\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        range(len(X)), \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=stratification_labels\n",
    "    )\n",
    "    \n",
    "    # Use these indices to filter the original DataFrame\n",
    "    #train_df = antibiogram_unique.iloc[train_indices]\n",
    "    #test_df = antibiogram_unique.iloc[test_indices]\n",
    "    \n",
    "    # Optionally, you can retrieve specific columns if needed\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    X_train = csr_matrix(X_train)\n",
    "    X_test = csr_matrix(X_test)\n",
    "\n",
    "    del X, y\n",
    "    del X_dna_subset, X_protein_subset, X_rrna_subset\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, kmer_size, train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Aztreonam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for antibiotic: aztreonam\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3170338/3331695195.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
      "/tmp/ipykernel_3170338/3331695195.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
      "/tmp/ipykernel_3170338/3331695195.py:47: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for kmer size 5\n"
     ]
    }
   ],
   "source": [
    "antibiogram_file=\"/data/dorothy/amr_ML/models_DRO/models_hypatia_beforeDeletion/aztreonam_QCed_metadata.csv\"\n",
    "output=\"./kmer_rf_xgboost_output.txt\"\n",
    "output_final=\"./models_dro/kmer_rf_xgboost_output_final.txt\"\n",
    "\n",
    "# -------------------------\n",
    "# Load the data\n",
    "# -------------------------\n",
    "antibiogram = pd.read_csv(antibiogram_file)\n",
    "antibiogram['phenotype'].value_counts()\n",
    "\n",
    "print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with open(output, 'w') as f:\n",
    "    print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\", file=f)\n",
    "    print(\"-\" * 40, file=f)\n",
    "\n",
    "# Remove antibiograms N phenotype\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'N']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'I']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'NS']\n",
    "\n",
    "antibiogram_unique = antibiogram.drop_duplicates(subset='id')\n",
    "\n",
    "# Convert 'Element' to binary values\n",
    "antibiotic_binary = antibiogram_unique['phenotype'].map({'S': 0, 'R': 1})\n",
    "antibiotic_binary = antibiotic_binary.to_numpy().astype(np.int8)\n",
    "\n",
    "\n",
    "# Find the indices of the elements in the sublist\n",
    "indices = [assemblies.index(element) for element in antibiogram_unique['id']]\n",
    "\n",
    "#New\n",
    "# Resetting index for antibiogram_gentamycin_unique\n",
    "antibiogram_unique.reset_index(drop=True, inplace=True)\n",
    "antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
    "indices_antibiograms=antibiogram_unique.index.tolist()\n",
    "\n",
    "#New\n",
    "# Extract the genus (first word) from the organism_name column\n",
    "antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
    "\n",
    "# Find how many from each genus are there\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()\n",
    "\n",
    "# Keep the indexes of each found genus\n",
    "genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n",
    "\n",
    "# Report total number of rows\n",
    "total_rows = antibiogram_unique.shape[0]\n",
    "\n",
    "\n",
    "# Get the antibiotic from the first row\n",
    "antibiotic_name = antibiogram_unique.loc[0, 'antibiotic']  # Assuming 'antibiotic' is the column name\n",
    "\n",
    "# List of genera to include in the output\n",
    "genera_list = ['Escherichia', 'Klebsiella', 'Acinetobacter', 'Staphylococcus', 'Pseudomonas', 'Enterobacter', 'Enterococcus']\n",
    "\n",
    "# Example genera_counts data (replace with actual values from your dataset)\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()  # Replace df with your actual DataFrame\n",
    "\n",
    "# Dictionary to store the results\n",
    "summary_data = {\n",
    "    'Total number': [total_rows],  # Total number of rows in your dataset\n",
    "    'Antibiotic': [antibiotic_name]  # Add the antibiotic name as a row\n",
    "}\n",
    "\n",
    "# Populate the dictionary with genus counts, defaulting to 0 if the genus is not present\n",
    "for genus in genera_list:\n",
    "    summary_data[genus] = [genera_counts.get(genus, 0)]\n",
    "    genus_res = antibiogram_unique.loc[antibiogram_unique[\"genus\"]==genus,\"phenotype\"].value_counts()\n",
    "    column_wanted=f\"{genus}_NumberOfResistantStrains\"\n",
    "    summary_data[column_wanted] = [genus_res.get(\"R\", 0)]\n",
    "    \n",
    "# Convert the dictionary to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "best_kmer_size = 5\n",
    "\n",
    "X_train, X_test, y_train, y_test, kmer_size, train_indices, test_indices = load_data(best_kmer_size)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split off validation set from training\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best config:\n",
      "n_estimators: 200\n",
      "max_depth: 6\n",
      "alpha: 0.2\n",
      "smoothing: 0.9\n",
      "threshold: 0.1\n",
      "FP: 91\n",
      "FN: 1\n",
      "F1: 0.9248366013071896\n",
      "\n",
      "Final Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       1.00      0.81      0.90       490\n",
      "           R       0.86      1.00      0.92       567\n",
      "\n",
      "    accuracy                           0.91      1057\n",
      "   macro avg       0.93      0.91      0.91      1057\n",
      "weighted avg       0.92      0.91      0.91      1057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "# Define grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'alpha': [0.2, 0.3],\n",
    "    'smoothing': [0.9, 0.95]\n",
    "}\n",
    "\n",
    "best_score = None\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_thresh = None\n",
    "\n",
    "# Grid search over all combinations\n",
    "for n_est, depth, alpha, smooth in product(param_grid['n_estimators'], param_grid['max_depth'], param_grid['alpha'], param_grid['smoothing']):\n",
    "    \n",
    "    # Step 1: Uncertainty weighting\n",
    "    base_model = xgb.XGBClassifier(n_estimators=100, max_depth=13, random_state=42)\n",
    "    base_model.fit(X_train2, y_train2)\n",
    "    y_probs = base_model.predict_proba(X_train2)[:, 1]\n",
    "    uncertainty = np.abs(0.5 - y_probs)\n",
    "\n",
    "    cutoff = int(len(y_train2) * alpha)\n",
    "    worst_indices = np.argsort(uncertainty)[:cutoff]\n",
    "\n",
    "    sample_weights = np.ones_like(y_train2)\n",
    "    sample_weights[worst_indices] = 5\n",
    "    sample_weights[y_train2 == 0] *= 2\n",
    "\n",
    "    y_smooth = y_train2 * smooth + (1 - smooth) / 2\n",
    "\n",
    "    # Step 2: DRO model\n",
    "    model = xgb.XGBRegressor(n_estimators=n_est, max_depth=depth, objective='reg:logistic', random_state=42)\n",
    "    model.fit(X_train2, y_smooth, sample_weight=sample_weights)\n",
    "\n",
    "    # Step 3: Threshold sweep with custom F1–FN tradeoff\n",
    "    lambda_fn = 0.01  # penalty for each FN\n",
    "    y_probs_test = model.predict(X_test)\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.7, 0.01):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Custom score: prioritize F1, penalize FN\n",
    "        score = f1 - lambda_fn * fn\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_thresh = thresh\n",
    "            best_params = {\n",
    "                'n_estimators': n_est,\n",
    "                'max_depth': depth,\n",
    "                'alpha': alpha,\n",
    "                'smoothing': smooth,\n",
    "                'threshold': thresh,\n",
    "                'FP': fp,\n",
    "                'FN': fn,\n",
    "                'F1': f1\n",
    "            }\n",
    "\n",
    "# Final report\n",
    "if best_model:\n",
    "    print(f\"\\n✅ Best config:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    y_pred_final = (best_model.predict(X_test) > best_thresh).astype(int)\n",
    "    print(\"\\nFinal Performance:\")\n",
    "    print(classification_report(y_test, y_pred_final, target_names=[\"S\", \"R\"]))\n",
    "else:\n",
    "    print(\"❌ No model found (this shouldn't happen).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold Sweep Results:\n",
      "Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\n",
      "---------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10   | 0.913 | 0.861 | 0.998 | 0.925 | 566 | 399 |  91 |   1\n",
      "0.15   | 0.929 | 0.888 | 0.993 | 0.938 | 563 | 419 |  71 |   4\n",
      "0.20   | 0.933 | 0.896 | 0.989 | 0.940 | 561 | 425 |  65 |   6\n",
      "0.25   | 0.935 | 0.903 | 0.984 | 0.942 | 558 | 430 |  60 |   9\n",
      "0.30   | 0.936 | 0.908 | 0.979 | 0.942 | 555 | 434 |  56 |  12\n",
      "0.35   | 0.935 | 0.911 | 0.974 | 0.941 | 552 | 436 |  54 |  15\n",
      "0.40   | 0.938 | 0.918 | 0.970 | 0.943 | 550 | 441 |  49 |  17\n",
      "0.45   | 0.937 | 0.925 | 0.959 | 0.942 | 544 | 446 |  44 |  23\n",
      "0.50   | 0.939 | 0.933 | 0.954 | 0.943 | 541 | 451 |  39 |  26\n",
      "0.55   | 0.937 | 0.937 | 0.945 | 0.941 | 536 | 454 |  36 |  31\n",
      "0.60   | 0.934 | 0.943 | 0.933 | 0.938 | 529 | 458 |  32 |  38\n",
      "0.65   | 0.928 | 0.946 | 0.919 | 0.932 | 521 | 460 |  30 |  46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"\\nThreshold Sweep Results:\")\n",
    "print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "y_probs_test = best_model.predict(X_test)\n",
    "for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "    y_pred = (y_probs_test > thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_xgboost_kmer_{best_kmer_size}_dro.pkl\", 'wb') as f:\n",
    "    \tpickle.dump(best_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for antibiotic: cefotaxime\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3170338/4284624723.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
      "/tmp/ipykernel_3170338/4284624723.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
      "/tmp/ipykernel_3170338/4284624723.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for kmer size 4\n",
      "\n",
      "✅ Best config:\n",
      "n_estimators: 100\n",
      "max_depth: 4\n",
      "alpha: 0.2\n",
      "smoothing: 0.95\n",
      "threshold: 0.1\n",
      "FP: 18\n",
      "FN: 2\n",
      "F1: 0.9765258215962441\n",
      "\n",
      "Final Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.99      0.90      0.94       187\n",
      "           R       0.96      1.00      0.98       418\n",
      "\n",
      "    accuracy                           0.97       605\n",
      "   macro avg       0.97      0.95      0.96       605\n",
      "weighted avg       0.97      0.97      0.97       605\n",
      "\n",
      "\n",
      "Threshold Sweep Results:\n",
      "Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\n",
      "---------------------------------------------------------------\n",
      "0.10   | 0.967 | 0.959 | 0.995 | 0.977 | 416 | 169 |  18 |   2\n",
      "0.15   | 0.970 | 0.972 | 0.986 | 0.979 | 412 | 175 |  12 |   6\n",
      "0.20   | 0.972 | 0.976 | 0.983 | 0.980 | 411 | 177 |  10 |   7\n",
      "0.25   | 0.972 | 0.976 | 0.983 | 0.980 | 411 | 177 |  10 |   7\n",
      "0.30   | 0.972 | 0.979 | 0.981 | 0.980 | 410 | 178 |   9 |   8\n",
      "0.35   | 0.972 | 0.981 | 0.978 | 0.980 | 409 | 179 |   8 |   9\n",
      "0.40   | 0.972 | 0.981 | 0.978 | 0.980 | 409 | 179 |   8 |   9\n",
      "0.45   | 0.969 | 0.981 | 0.974 | 0.977 | 407 | 179 |   8 |  11\n",
      "0.50   | 0.967 | 0.981 | 0.971 | 0.976 | 406 | 179 |   8 |  12\n",
      "0.55   | 0.967 | 0.981 | 0.971 | 0.976 | 406 | 179 |   8 |  12\n",
      "0.60   | 0.964 | 0.981 | 0.967 | 0.973 | 404 | 179 |   8 |  14\n",
      "0.65   | 0.955 | 0.983 | 0.952 | 0.967 | 398 | 180 |   7 |  20\n"
     ]
    }
   ],
   "source": [
    "###Cefotaxime\n",
    "antibiogram_file=\"/data/dorothy/amr_ML/models_DRO/models_hypatia_beforeDeletion/cefotaxime_QCed_metadata.csv\"\n",
    "output=\"./kmer_rf_xgboost_output.txt\"\n",
    "output_final=\"./models_dro/kmer_rf_xgboost_output_final.txt\"\n",
    "\n",
    "# -------------------------\n",
    "# Load the data\n",
    "# -------------------------\n",
    "antibiogram = pd.read_csv(antibiogram_file)\n",
    "antibiogram['phenotype'].value_counts()\n",
    "\n",
    "print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with open(output, 'w') as f:\n",
    "    print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\", file=f)\n",
    "    print(\"-\" * 40, file=f)\n",
    "\n",
    "# Remove antibiograms N phenotype\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'N']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'I']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'NS']\n",
    "\n",
    "antibiogram_unique = antibiogram.drop_duplicates(subset='id')\n",
    "\n",
    "# Convert 'Element' to binary values\n",
    "antibiotic_binary = antibiogram_unique['phenotype'].map({'S': 0, 'R': 1})\n",
    "antibiotic_binary = antibiotic_binary.to_numpy().astype(np.int8)\n",
    "\n",
    "\n",
    "# Find the indices of the elements in the sublist\n",
    "indices = [assemblies.index(element) for element in antibiogram_unique['id']]\n",
    "\n",
    "#New\n",
    "# Resetting index for antibiogram_gentamycin_unique\n",
    "antibiogram_unique.reset_index(drop=True, inplace=True)\n",
    "antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
    "indices_antibiograms=antibiogram_unique.index.tolist()\n",
    "\n",
    "#New\n",
    "# Extract the genus (first word) from the organism_name column\n",
    "antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
    "\n",
    "# Find how many from each genus are there\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()\n",
    "\n",
    "# Keep the indexes of each found genus\n",
    "genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n",
    "\n",
    "# Report total number of rows\n",
    "total_rows = antibiogram_unique.shape[0]\n",
    "\n",
    "\n",
    "# Get the antibiotic from the first row\n",
    "antibiotic_name = antibiogram_unique.loc[0, 'antibiotic']  # Assuming 'antibiotic' is the column name\n",
    "\n",
    "# List of genera to include in the output\n",
    "genera_list = ['Escherichia', 'Klebsiella', 'Acinetobacter', 'Staphylococcus', 'Pseudomonas', 'Enterobacter', 'Enterococcus']\n",
    "\n",
    "# Example genera_counts data (replace with actual values from your dataset)\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()  # Replace df with your actual DataFrame\n",
    "\n",
    "# Dictionary to store the results\n",
    "summary_data = {\n",
    "    'Total number': [total_rows],  # Total number of rows in your dataset\n",
    "    'Antibiotic': [antibiotic_name]  # Add the antibiotic name as a row\n",
    "}\n",
    "\n",
    "# Populate the dictionary with genus counts, defaulting to 0 if the genus is not present\n",
    "for genus in genera_list:\n",
    "    summary_data[genus] = [genera_counts.get(genus, 0)]\n",
    "    genus_res = antibiogram_unique.loc[antibiogram_unique[\"genus\"]==genus,\"phenotype\"].value_counts()\n",
    "    column_wanted=f\"{genus}_NumberOfResistantStrains\"\n",
    "    summary_data[column_wanted] = [genus_res.get(\"R\", 0)]\n",
    "    \n",
    "# Convert the dictionary to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "best_kmer_size = 4\n",
    "\n",
    "X_train, X_test, y_train, y_test, kmer_size, train_indices, test_indices = load_data(best_kmer_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split off validation set from training\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "# Define grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'alpha': [0.2, 0.3],\n",
    "    'smoothing': [0.9, 0.95]\n",
    "}\n",
    "\n",
    "best_score = None\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_thresh = None\n",
    "\n",
    "# Grid search over all combinations\n",
    "for n_est, depth, alpha, smooth in product(param_grid['n_estimators'], param_grid['max_depth'], param_grid['alpha'], param_grid['smoothing']):\n",
    "    \n",
    "    # Step 1: Uncertainty weighting\n",
    "    base_model = xgb.XGBClassifier(n_estimators=100, max_depth=13, random_state=42)\n",
    "    base_model.fit(X_train2, y_train2)\n",
    "    y_probs = base_model.predict_proba(X_train2)[:, 1]\n",
    "    uncertainty = np.abs(0.5 - y_probs)\n",
    "\n",
    "    cutoff = int(len(y_train2) * alpha)\n",
    "    worst_indices = np.argsort(uncertainty)[:cutoff]\n",
    "\n",
    "    sample_weights = np.ones_like(y_train2)\n",
    "    sample_weights[worst_indices] = 5\n",
    "    sample_weights[y_train2 == 0] *= 2\n",
    "\n",
    "    y_smooth = y_train2 * smooth + (1 - smooth) / 2\n",
    "\n",
    "    # Step 2: DRO model\n",
    "    model = xgb.XGBRegressor(n_estimators=n_est, max_depth=depth, objective='reg:logistic', random_state=42)\n",
    "    model.fit(X_train2, y_smooth, sample_weight=sample_weights)\n",
    "\n",
    "    # Step 3: Threshold sweep with custom F1–FN tradeoff\n",
    "    lambda_fn = 0.01  # penalty for each FN\n",
    "    y_probs_test = model.predict(X_test)\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.7, 0.01):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Custom score: prioritize F1, penalize FN\n",
    "        score = f1 - lambda_fn * fn\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_thresh = thresh\n",
    "            best_params = {\n",
    "                'n_estimators': n_est,\n",
    "                'max_depth': depth,\n",
    "                'alpha': alpha,\n",
    "                'smoothing': smooth,\n",
    "                'threshold': thresh,\n",
    "                'FP': fp,\n",
    "                'FN': fn,\n",
    "                'F1': f1\n",
    "            }\n",
    "\n",
    "# Final report\n",
    "if best_model:\n",
    "    print(f\"\\n✅ Best config:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    y_pred_final = (best_model.predict(X_test) > best_thresh).astype(int)\n",
    "    print(\"\\nFinal Performance:\")\n",
    "    print(classification_report(y_test, y_pred_final, target_names=[\"S\", \"R\"]))\n",
    "else:\n",
    "    print(\"❌ No model found (this shouldn't happen).\")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"\\nThreshold Sweep Results:\")\n",
    "print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "y_probs_test = best_model.predict(X_test)\n",
    "for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "    y_pred = (y_probs_test > thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\")\n",
    "# Add this code after the threshold sweep results printing\n",
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_threshold_sweep_results.txt\", 'w') as f:\n",
    "    print(\"\\nThreshold Sweep Results:\", file=f)\n",
    "    print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\", file=f)\n",
    "    print(\"---------------------------------------------------------------\", file=f)\n",
    "    y_probs_test = best_model.predict(X_test)\n",
    "    for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\", file=f)\n",
    "        \n",
    "        \n",
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_xgboost_kmer_{best_kmer_size}_dro.pkl\", 'wb') as f:\n",
    "    \tpickle.dump(best_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for antibiotic: gentamicin\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3183208/2065259621.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
      "/tmp/ipykernel_3183208/2065259621.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
      "/tmp/ipykernel_3183208/2065259621.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for kmer size 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_est, depth, alpha, smooth \u001b[38;5;129;01min\u001b[39;00m product(param_grid[\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m], param_grid[\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m], param_grid[\u001b[33m'\u001b[39m\u001b[33malpha\u001b[39m\u001b[33m'\u001b[39m], param_grid[\u001b[33m'\u001b[39m\u001b[33msmoothing\u001b[39m\u001b[33m'\u001b[39m]):\n\u001b[32m    114\u001b[39m \n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Step 1: Uncertainty weighting\u001b[39;00m\n\u001b[32m    116\u001b[39m     base_model = xgb.XGBClassifier(n_estimators=\u001b[32m100\u001b[39m, max_depth=\u001b[32m13\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m     y_probs = base_model.predict_proba(X_train2)[:, \u001b[32m1\u001b[39m]\n\u001b[32m    119\u001b[39m     uncertainty = np.abs(\u001b[32m0.5\u001b[39m - y_probs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cursor-python312/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cursor-python312/lib/python3.12/site-packages/xgboost/sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cursor-python312/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cursor-python312/lib/python3.12/site-packages/xgboost/training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cursor-python312/lib/python3.12/site-packages/xgboost/core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "###Cefotaxime\n",
    "antibiogram_file=\"/data/dorothy/amr_ML/models_DRO/models_hypatia_beforeDeletion/gentamicin_QCed_metadata.csv\"\n",
    "output=\"./kmer_rf_xgboost_output.txt\"\n",
    "output_final=\"./models_dro/kmer_rf_xgboost_output_final.txt\"\n",
    "\n",
    "# -------------------------\n",
    "# Load the data\n",
    "# -------------------------\n",
    "antibiogram = pd.read_csv(antibiogram_file)\n",
    "antibiogram['phenotype'].value_counts()\n",
    "\n",
    "print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with open(output, 'w') as f:\n",
    "    print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\", file=f)\n",
    "    print(\"-\" * 40, file=f)\n",
    "\n",
    "# Remove antibiograms N phenotype\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'N']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'I']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'NS']\n",
    "\n",
    "antibiogram_unique = antibiogram.drop_duplicates(subset='id')\n",
    "\n",
    "# Convert 'Element' to binary values\n",
    "antibiotic_binary = antibiogram_unique['phenotype'].map({'S': 0, 'R': 1})\n",
    "antibiotic_binary = antibiotic_binary.to_numpy().astype(np.int8)\n",
    "\n",
    "\n",
    "# Find the indices of the elements in the sublist\n",
    "indices = [assemblies.index(element) for element in antibiogram_unique['id']]\n",
    "\n",
    "#New\n",
    "# Resetting index for antibiogram_gentamycin_unique\n",
    "antibiogram_unique.reset_index(drop=True, inplace=True)\n",
    "antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
    "indices_antibiograms=antibiogram_unique.index.tolist()\n",
    "\n",
    "#New\n",
    "# Extract the genus (first word) from the organism_name column\n",
    "antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
    "\n",
    "# Find how many from each genus are there\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()\n",
    "\n",
    "# Keep the indexes of each found genus\n",
    "genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n",
    "\n",
    "# Report total number of rows\n",
    "total_rows = antibiogram_unique.shape[0]\n",
    "\n",
    "\n",
    "# Get the antibiotic from the first row\n",
    "antibiotic_name = antibiogram_unique.loc[0, 'antibiotic']  # Assuming 'antibiotic' is the column name\n",
    "\n",
    "# List of genera to include in the output\n",
    "genera_list = ['Escherichia', 'Klebsiella', 'Acinetobacter', 'Staphylococcus', 'Pseudomonas', 'Enterobacter', 'Enterococcus']\n",
    "\n",
    "# Example genera_counts data (replace with actual values from your dataset)\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()  # Replace df with your actual DataFrame\n",
    "\n",
    "# Dictionary to store the results\n",
    "summary_data = {\n",
    "    'Total number': [total_rows],  # Total number of rows in your dataset\n",
    "    'Antibiotic': [antibiotic_name]  # Add the antibiotic name as a row\n",
    "}\n",
    "\n",
    "# Populate the dictionary with genus counts, defaulting to 0 if the genus is not present\n",
    "for genus in genera_list:\n",
    "    summary_data[genus] = [genera_counts.get(genus, 0)]\n",
    "    genus_res = antibiogram_unique.loc[antibiogram_unique[\"genus\"]==genus,\"phenotype\"].value_counts()\n",
    "    column_wanted=f\"{genus}_NumberOfResistantStrains\"\n",
    "    summary_data[column_wanted] = [genus_res.get(\"R\", 0)]\n",
    "    \n",
    "# Convert the dictionary to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "best_kmer_size = 5\n",
    "\n",
    "X_train, X_test, y_train, y_test, kmer_size, train_indices, test_indices = load_data(best_kmer_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split off validation set from training\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "# Define grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'alpha': [0.2, 0.3],\n",
    "    'smoothing': [0.9, 0.95]\n",
    "}\n",
    "\n",
    "best_score = None\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_thresh = None\n",
    "\n",
    "# Grid search over all combinations\n",
    "for n_est, depth, alpha, smooth in product(param_grid['n_estimators'], param_grid['max_depth'], param_grid['alpha'], param_grid['smoothing']):\n",
    "    \n",
    "    # Step 1: Uncertainty weighting\n",
    "    base_model = xgb.XGBClassifier(n_estimators=100, max_depth=13, random_state=42)\n",
    "    base_model.fit(X_train2, y_train2)\n",
    "    y_probs = base_model.predict_proba(X_train2)[:, 1]\n",
    "    uncertainty = np.abs(0.5 - y_probs)\n",
    "\n",
    "    cutoff = int(len(y_train2) * alpha)\n",
    "    worst_indices = np.argsort(uncertainty)[:cutoff]\n",
    "\n",
    "    sample_weights = np.ones_like(y_train2)\n",
    "    sample_weights[worst_indices] = 5\n",
    "    sample_weights[y_train2 == 0] *= 2\n",
    "\n",
    "    y_smooth = y_train2 * smooth + (1 - smooth) / 2\n",
    "\n",
    "    # Step 2: DRO model\n",
    "    model = xgb.XGBRegressor(n_estimators=n_est, max_depth=depth, objective='reg:logistic', random_state=42)\n",
    "    model.fit(X_train2, y_smooth, sample_weight=sample_weights)\n",
    "\n",
    "    # Step 3: Threshold sweep with custom F1–FN tradeoff\n",
    "    lambda_fn = 0.01  # penalty for each FN\n",
    "    y_probs_test = model.predict(X_test)\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.7, 0.01):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Custom score: prioritize F1, penalize FN\n",
    "        score = f1 - lambda_fn * fn\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_thresh = thresh\n",
    "            best_params = {\n",
    "                'n_estimators': n_est,\n",
    "                'max_depth': depth,\n",
    "                'alpha': alpha,\n",
    "                'smoothing': smooth,\n",
    "                'threshold': thresh,\n",
    "                'FP': fp,\n",
    "                'FN': fn,\n",
    "                'F1': f1\n",
    "            }\n",
    "\n",
    "# Final report\n",
    "if best_model:\n",
    "    print(f\"\\n✅ Best config:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    y_pred_final = (best_model.predict(X_test) > best_thresh).astype(int)\n",
    "    print(\"\\nFinal Performance:\")\n",
    "    print(classification_report(y_test, y_pred_final, target_names=[\"S\", \"R\"]))\n",
    "else:\n",
    "    print(\"❌ No model found (this shouldn't happen).\")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"\\nThreshold Sweep Results:\")\n",
    "print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "y_probs_test = best_model.predict(X_test)\n",
    "for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "    y_pred = (y_probs_test > thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\")\n",
    "# Add this code after the threshold sweep results printing\n",
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_threshold_sweep_results.txt\", 'w') as f:\n",
    "    print(\"\\nThreshold Sweep Results:\", file=f)\n",
    "    print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\", file=f)\n",
    "    print(\"---------------------------------------------------------------\", file=f)\n",
    "    y_probs_test = best_model.predict(X_test)\n",
    "    for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\", file=f)\n",
    "        \n",
    "        \n",
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_xgboost_kmer_{best_kmer_size}_dro.pkl\", 'wb') as f:\n",
    "    \tpickle.dump(best_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m output_final=\u001b[33m\"\u001b[39m\u001b[33m./models_dro/kmer_rf_xgboost_output_final.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# -------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m antibiogram = \u001b[43mpd\u001b[49m.read_csv(antibiogram_file)\n\u001b[32m     10\u001b[39m antibiogram[\u001b[33m'\u001b[39m\u001b[33mphenotype\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPreparing data for antibiotic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mantibiogram[\u001b[33m'\u001b[39m\u001b[33mantibiotic\u001b[39m\u001b[33m'\u001b[39m].iloc[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "###Cefotaxime\n",
    "antibiogram_file=\"/data/dorothy/amr_ML/models_DRO/models_hypatia_beforeDeletion/ampicillin_QCed_metadata.csv\"\n",
    "output=\"./kmer_rf_xgboost_output.txt\"\n",
    "output_final=\"./models_dro/kmer_rf_xgboost_output_final.txt\"\n",
    "\n",
    "# -------------------------\n",
    "# Load the data\n",
    "# -------------------------\n",
    "antibiogram = pd.read_csv(antibiogram_file)\n",
    "antibiogram['phenotype'].value_counts()\n",
    "\n",
    "print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "with open(output, 'w') as f:\n",
    "    print(f\"Preparing data for antibiotic: {antibiogram['antibiotic'].iloc[0]}\", file=f)\n",
    "    print(\"-\" * 40, file=f)\n",
    "\n",
    "# Remove antibiograms N phenotype\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'N']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'I']\n",
    "antibiogram = antibiogram[antibiogram['phenotype'] != 'NS']\n",
    "\n",
    "antibiogram_unique = antibiogram.drop_duplicates(subset='id')\n",
    "\n",
    "# Convert 'Element' to binary values\n",
    "antibiotic_binary = antibiogram_unique['phenotype'].map({'S': 0, 'R': 1})\n",
    "antibiotic_binary = antibiotic_binary.to_numpy().astype(np.int8)\n",
    "\n",
    "\n",
    "# Find the indices of the elements in the sublist\n",
    "indices = [assemblies.index(element) for element in antibiogram_unique['id']]\n",
    "\n",
    "#New\n",
    "# Resetting index for antibiogram_gentamycin_unique\n",
    "antibiogram_unique.reset_index(drop=True, inplace=True)\n",
    "antibiogram_unique['organism_name'] = antibiogram_unique['organism_name'].replace('E.coli and', 'Escherichia coli')\n",
    "indices_antibiograms=antibiogram_unique.index.tolist()\n",
    "\n",
    "#New\n",
    "# Extract the genus (first word) from the organism_name column\n",
    "antibiogram_unique['genus'] = antibiogram_unique['organism_name'].str.split().str[0]\n",
    "\n",
    "# Find how many from each genus are there\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()\n",
    "\n",
    "# Keep the indexes of each found genus\n",
    "genera_indices = antibiogram_unique.groupby('genus').apply(lambda x: x.index.tolist())\n",
    "\n",
    "# Report total number of rows\n",
    "total_rows = antibiogram_unique.shape[0]\n",
    "\n",
    "\n",
    "# Get the antibiotic from the first row\n",
    "antibiotic_name = antibiogram_unique.loc[0, 'antibiotic']  # Assuming 'antibiotic' is the column name\n",
    "\n",
    "# List of genera to include in the output\n",
    "genera_list = ['Escherichia', 'Klebsiella', 'Acinetobacter', 'Staphylococcus', 'Pseudomonas', 'Enterobacter', 'Enterococcus']\n",
    "\n",
    "# Example genera_counts data (replace with actual values from your dataset)\n",
    "genera_counts = antibiogram_unique['genus'].value_counts()  # Replace df with your actual DataFrame\n",
    "\n",
    "# Dictionary to store the results\n",
    "summary_data = {\n",
    "    'Total number': [total_rows],  # Total number of rows in your dataset\n",
    "    'Antibiotic': [antibiotic_name]  # Add the antibiotic name as a row\n",
    "}\n",
    "\n",
    "# Populate the dictionary with genus counts, defaulting to 0 if the genus is not present\n",
    "for genus in genera_list:\n",
    "    summary_data[genus] = [genera_counts.get(genus, 0)]\n",
    "    genus_res = antibiogram_unique.loc[antibiogram_unique[\"genus\"]==genus,\"phenotype\"].value_counts()\n",
    "    column_wanted=f\"{genus}_NumberOfResistantStrains\"\n",
    "    summary_data[column_wanted] = [genus_res.get(\"R\", 0)]\n",
    "    \n",
    "# Convert the dictionary to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "best_kmer_size = 4\n",
    "\n",
    "X_train, X_test, y_train, y_test, kmer_size, train_indices, test_indices = load_data(best_kmer_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split off validation set from training\n",
    "X_train2, X_val, y_train2, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "# Define grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'alpha': [0.2, 0.3],\n",
    "    'smoothing': [0.9, 0.95]\n",
    "}\n",
    "\n",
    "best_score = None\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_thresh = None\n",
    "\n",
    "# Grid search over all combinations\n",
    "for n_est, depth, alpha, smooth in product(param_grid['n_estimators'], param_grid['max_depth'], param_grid['alpha'], param_grid['smoothing']):\n",
    "    \n",
    "    # Step 1: Uncertainty weighting\n",
    "    base_model = xgb.XGBClassifier(n_estimators=100, max_depth=13, random_state=42)\n",
    "    base_model.fit(X_train2, y_train2)\n",
    "    y_probs = base_model.predict_proba(X_train2)[:, 1]\n",
    "    uncertainty = np.abs(0.5 - y_probs)\n",
    "\n",
    "    cutoff = int(len(y_train2) * alpha)\n",
    "    worst_indices = np.argsort(uncertainty)[:cutoff]\n",
    "\n",
    "    sample_weights = np.ones_like(y_train2)\n",
    "    sample_weights[worst_indices] = 5\n",
    "    sample_weights[y_train2 == 0] *= 2\n",
    "\n",
    "    y_smooth = y_train2 * smooth + (1 - smooth) / 2\n",
    "\n",
    "    # Step 2: DRO model\n",
    "    model = xgb.XGBRegressor(n_estimators=n_est, max_depth=depth, objective='reg:logistic', random_state=42)\n",
    "    model.fit(X_train2, y_smooth, sample_weight=sample_weights)\n",
    "\n",
    "    # Step 3: Threshold sweep with custom F1–FN tradeoff\n",
    "    lambda_fn = 0.01  # penalty for each FN\n",
    "    y_probs_test = model.predict(X_test)\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.7, 0.01):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Custom score: prioritize F1, penalize FN\n",
    "        score = f1 - lambda_fn * fn\n",
    "\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_thresh = thresh\n",
    "            best_params = {\n",
    "                'n_estimators': n_est,\n",
    "                'max_depth': depth,\n",
    "                'alpha': alpha,\n",
    "                'smoothing': smooth,\n",
    "                'threshold': thresh,\n",
    "                'FP': fp,\n",
    "                'FN': fn,\n",
    "                'F1': f1\n",
    "            }\n",
    "\n",
    "# Final report\n",
    "if best_model:\n",
    "    print(f\"\\n✅ Best config:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    y_pred_final = (best_model.predict(X_test) > best_thresh).astype(int)\n",
    "    print(\"\\nFinal Performance:\")\n",
    "    print(classification_report(y_test, y_pred_final, target_names=[\"S\", \"R\"]))\n",
    "else:\n",
    "    print(\"❌ No model found (this shouldn't happen).\")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "print(\"\\nThreshold Sweep Results:\")\n",
    "print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "y_probs_test = best_model.predict(X_test)\n",
    "for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "    y_pred = (y_probs_test > thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\")\n",
    "# Add this code after the threshold sweep results printing\n",
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_threshold_sweep_results.txt\", 'w') as f:\n",
    "    print(\"\\nThreshold Sweep Results:\", file=f)\n",
    "    print(\"Thresh | Acc   | Prec  | Rec   | F1    | TP  | TN  | FP  | FN\", file=f)\n",
    "    print(\"---------------------------------------------------------------\", file=f)\n",
    "    y_probs_test = best_model.predict(X_test)\n",
    "    for thresh in np.arange(0.1, 0.7, 0.05):\n",
    "        y_pred = (y_probs_test > thresh).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{thresh:.2f}   | {acc:.3f} | {prec:.3f} | {rec:.3f} | {f1:.3f} | {tp:3d} | {tn:3d} | {fp:3d} | {fn:3d}\", file=f)\n",
    "        \n",
    "        \n",
    "with open(f\"./models_dro/{antibiogram['antibiotic'].iloc[0].split(' ')[0]}_xgboost_kmer_{best_kmer_size}_dro.pkl\", 'wb') as f:\n",
    "    \tpickle.dump(best_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
