{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33c7f89-16d8-4553-8c3e-8dc80ebdb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d59c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize path variables\n",
    "strain_metadata = pd.read_csv(\"../data_acquisition/Assemblies/strain_metadata_filtered.csv\")\n",
    "\n",
    "reference_genomes = {\n",
    "    'Klebsiella': 'Klebsiella_pneumoniae',\n",
    "    'Escherichia': 'Escherichia_coli',\n",
    "    'Enterobacter': 'Enterobacter_cloacae',\n",
    "    'Pseudomonas': 'Pseudomonas_aeruginosa',\n",
    "    'Staphylococcus': 'Staphylococcus_aureus',\n",
    "    'Acinetobacter': 'Acinetobacter_baumannii',\n",
    "    'Enterococcus': 'Enterococcus_faecium'\n",
    "}\n",
    "\n",
    "assembly = os.path.basename(snakemake.input[0])\n",
    "\n",
    "# get genus from genus column of strain_metadata based on assembly variable\n",
    "# if assembly is equal to sra, assembly, or biosample, return genus\n",
    "mask = (strain_metadata[\"sra\"] == assembly.replace(\".fna\", \"\")) | \\\n",
    "        (strain_metadata[\"assembly\"] == assembly.replace(\".fna\", \"\")) | \\\n",
    "        (strain_metadata[\"biosample\"] == assembly.replace(\".fna\", \"\"))\n",
    "genus = strain_metadata.loc[mask, \"genus\"].to_string(index=False).strip() if not strain_metadata.loc[mask, \"genus\"].empty else None\n",
    "\n",
    "ref_genome = reference_genomes[genus]\n",
    "dir_name = f\"{snakemake.params[0]}{ref_genome}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3522e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rRNA copies as fasta files\n",
    "copies_length = []\n",
    "protein_length = {}\n",
    "for fasta in os.listdir(dir_name):\n",
    "    match = re.match(r'^(\\d+)\\.fasta$', fasta)\n",
    "    if match:\n",
    "        copies_length.append(f\"{dir_name}{match.group(1)}.fasta\")\n",
    "\n",
    "\n",
    "for copy in copies_length:\n",
    "    # Find length of each protein/dna sequence on db_file\n",
    "    with open(copy, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                protein_id = line.split(' ')[0][1:].rstrip()\n",
    "                protein_length[protein_id] = 0\n",
    "            else:\n",
    "                protein_length[protein_id] += len(line.strip())\n",
    "\n",
    "\n",
    "# Run blastn on the assembly file against all databases in dir_name folder and filter the results\n",
    "for db in os.listdir(dir_name):\n",
    "    match = re.match(r'^(db\\d+)\\.ndb$', db)\n",
    "    if match:\n",
    "        os.system(f\"../tools/ncbi-blast-2.15.0+/bin/blastn -query f{snakemake.input[0]} \\\n",
    "                  -db {dir_name}{match.group(1)} -outfmt \\\"6 std qseq sseq\\\" -out {dir_name}{assembly}_{match.group(1)}.out -num_threads 4\")\n",
    "        \n",
    "        # # Create a dataframe from the BLAST file\n",
    "        if os.path.getsize(f\"{dir_name}{assembly}_{match.group(1)}.out\") == 0:\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_csv(f\"{dir_name}{assembly}_{match.group(1)}.out\", sep='\\t', header=None)\n",
    "        \n",
    "            df.columns = ['query_id', 'subject_id', 'pct_identity', 'aln_length', 'n_of_mismatches', 'gap_openings', \n",
    "                'q_start', 'q_end', 's_start', 's_end', 'e_value', 'bit_score', 'q_seq', 's_seq']\n",
    "            \n",
    "            \n",
    "            # Create a new column in the dataframe with the total percent identity (aln_length / protein length) protein name is based on second column\n",
    "            df['pct_coverage'] = df.apply(lambda row: (row['aln_length'] - row['gap_openings']) / protein_length[row['subject_id']], axis=1) * 100\n",
    "\n",
    "            # filter the dataframe to keep total_pct_identity > 50 and pct_identity > 70\n",
    "            df = df[(df['pct_coverage'] > 80) & (df['pct_identity'] > 80)]\n",
    "            \n",
    "\n",
    "            df.to_csv(f\"{dir_name}{assembly}_{match.group(1)}_filtered.out\", sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a0659ed-6f4f-4bef-8a22-315262cb7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make regex to match the file name f'.db{number}'\n",
    "files = []\n",
    "for db in os.listdir(dir_name):\n",
    "    if re.match(assembly +  r'_db(\\d+)\\_filtered.out$', db):\n",
    "            file = os.path.join(dir_name, db)\n",
    "            files.append(file)\n",
    "\n",
    "blastn_data = {}\n",
    "\n",
    "for file in files:\n",
    "    if os.path.getsize(file) > 0:\n",
    "        df = pd.read_csv(file, delimiter = \"\\t\" , header=None)\n",
    "        blastn_data[df[1].iloc[0]] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e55f684-3f75-4b3e-96b3-aa9990d4cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitscores = []\n",
    "\n",
    "for key, values in blastn_data.items():\n",
    "    max_index = max(values[11])\n",
    "    bitscores.append(max_index)\n",
    "\n",
    "\n",
    "data = pd.DataFrame({'contig': [df.iloc[0, 0] for df in blastn_data.values()],\n",
    "        'gene': blastn_data.keys(),\n",
    "        'bitscore': bitscores,\n",
    "        'length': None,\n",
    "        'sequence': None,\n",
    "        'start': None,\n",
    "        'end': None})\n",
    "data = data.sort_values(by='bitscore', ascending=False)\n",
    "\n",
    "length = []\n",
    "for key in data['gene']:\n",
    "    length.append(protein_length[key])\n",
    "\n",
    "data['length'] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0ce870a-5298-4e26-a9ea-79955290208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              contig                      gene  bitscore  length  \\\n",
      "2  JAKXYI010000001.1  5sEscherichia_coli_copy1       217     120   \n",
      "4  JAKXYI010000001.1  5sEscherichia_coli_copy3       206     120   \n",
      "6  JAKXYI010000001.1  5sEscherichia_coli_copy4       206     120   \n",
      "0  JAKXYI010000001.1  5sEscherichia_coli_copy8       202     120   \n",
      "3  JAKXYI010000001.1  5sEscherichia_coli_copy6       202     120   \n",
      "1  JAKXYI010000001.1  5sEscherichia_coli_copy7       202     120   \n",
      "5  JAKXYI010000001.1  5sEscherichia_coli_copy5       202     120   \n",
      "7  JAKXYI010000001.1  5sEscherichia_coli_copy2       200     120   \n",
      "\n",
      "                                            sequence   start     end  \n",
      "2  ATGTCTGGCAGTTCCCTACTCTCGCATGGGGAAACCCCACACTACC...     117     236  \n",
      "4  GTAGCGCGGTGGTCCCACCTGACCCCATGCCGAACTCAGAAGTGAA...  189057  189164  \n",
      "6  TAGCGCGGCGGTCCCACCTGACCCCATGCCGAACTCAGAAGTGAAA...    4157    4263  \n",
      "0  XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...       0       0  \n",
      "3  XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...       0       0  \n",
      "1  XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...       0       0  \n",
      "5  XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...       0       0  \n",
      "7  XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX...       0       0  \n"
     ]
    }
   ],
   "source": [
    "unique_coordinates = set()\n",
    "\n",
    "if len(blastn_data) == 0:\n",
    "    for i in range(len(files)):\n",
    "        # read each fasta file (i+1.fasta) and count the sequence length\n",
    "        with open(f\"{dir_name}{i+1}.fasta\", 'r') as f:\n",
    "            length = 0\n",
    "            for line in f:\n",
    "                if not line.startswith('>'):\n",
    "                    length += len(line.strip())\n",
    "        \n",
    "        data.at[i, 'sequence'] = 'X'*length\n",
    "        data.at[i, 'start'] = 0\n",
    "        data.at[i, 'end'] = 0\n",
    "        data.at[i, 'length'] = length\n",
    "        data.at[i, 'bitscore'] = 0\n",
    "        data.at[i, 'gene'] = None\n",
    "        data.at[i, 'contig'] = None\n",
    "else:\n",
    "    for index, row in data.iterrows():\n",
    "        subject_id = row['gene']\n",
    "\n",
    "        if blastn_data[subject_id].empty:\n",
    "            data.at[index, 'sequence'] = 'X'*data['length'].iloc[index]\n",
    "            data.at[index, 'start'] = 0\n",
    "            data.at[index, 'end'] = 0\n",
    "        else:\n",
    "            max_bitscore = blastn_data[subject_id].sort_values(by = 11, ascending=False)\n",
    "            max_bitscore = max_bitscore.iloc[0]\n",
    "\n",
    "            if max_bitscore[8] > max_bitscore[9]:\n",
    "                # reverse complement the sequence\n",
    "                sequence = max_bitscore[12]\n",
    "                sequence = sequence[::-1]\n",
    "                sequence = sequence.translate(str.maketrans('ATCG', 'TAGC'))\n",
    "            else:\n",
    "                sequence = max_bitscore[12]\n",
    "            \n",
    "            data.at[index, 'sequence'] = sequence\n",
    "            data.at[index, 'start'] = max_bitscore[6]\n",
    "            data.at[index, 'end'] = max_bitscore[7]\n",
    "\n",
    "            unique_coordinates.add((max_bitscore[0], max_bitscore[6], max_bitscore[7]))\n",
    "            \n",
    "            # Remove the coordinates from the blastn_data, and also when start and end coords are within the range of the previous coordinates\n",
    "            for subject_id, df in blastn_data.items():\n",
    "                blastn_data[subject_id] = df[~df[[0, 6, 7]].apply(\n",
    "                    lambda x: (x[0], x[6], x[7]) in unique_coordinates or (x[6] >= max_bitscore[6] and x[7] <= max_bitscore[7]), axis=1\n",
    "                )]\n",
    "                # add empty dataframes to the dictionary to avoid key errors\n",
    "                if blastn_data[subject_id].empty:\n",
    "                    blastn_data[subject_id] = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e11ad-4c92-49e2-b2fe-386decedebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='gene', ascending=True)\n",
    "\n",
    "final_seqs = ''\n",
    "for index, row in data.iterrows():\n",
    "    final_seqs = str(final_seqs) + str(row['sequence'])\n",
    "\n",
    "with open(snakemake.output[0], 'w') as f:\n",
    "    f.write(final_seqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
